---
layout: post
title: "Introduction to Machine Learning - Part 1"
date: 2017-08-23
---

Hey there you beautiful ladies and gentlemen, señoras y señores, damen und herren, 女士们(們) 先生们(們 ! Hope you have a great day. I am now making a "series" of posts regarding Machine Learning. They will vary from the conceptual level, the low level technicalities, to some inspirations to applications. 


### Setting the stage - how are the buzzwords connected?

Machine Learning, Artificial Intelligence, Deep Learning, Big Data! There is such a great hype for these techniques, specially among non-technical folks. There is a conception that these techniques are able to solve all kinds of problems, in a hassle free way. People are going to loose their jobs and we will soon end up as in the Matrix. I will try to make an own post regarding this, discussing if machines really can be intelligent. For now, assume that that's not the case. It will be blood, sweat, toil and tears to pull off any real-world Machine Learning project. 

There are some rather blurred lines between the concepts of Machine Learning (ML), Artificial Intelligence (AI), Deep Learning and Big Data. As the illustration below shows us, Deep Learning is a subgroup within ML. ML is again a subgroup within AI. The figure is collected from the [Nvidia blog](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/).

![center](/figs/2017-08-23-intro-ML/Deep_Learning_Icons_R5_PNG.png)

#### But what about Big Data? 
Big data however, is more on the side. We don't neccesarily need Big data in order to do some work on AI. But if we want to use huge datasets, Big data, it gets tricky to use traditional methods to handle this data. Thus there are created different techniques to deal with this. Both for storing and processing, we need to think differently. In this manner, Big data is more about how to set up your architectures than the core statistical ideas of AI, ML and Deep Learning. 


### "Defining AI"

We leave Big data for now in this post, and go further with the others. I personally think it is tricky to give a precise and crisp definition of the concepts, but for all of the current AI techniques we most often have the following:
 * A data driven approach, where we use statistics to construct models that can replicate data we get as input.

Let's think of an example from Image Recognition. Our problem is to make an automatical selection between pictures birds and cows. How we will approach this with AI, is to throug thousands of pictures of different birds and cows into an algorithm that trains a model to determine the difference. In this manner, we "learn" our model, by adding one picture at the time. In the end, we hopefully have a model that can take in an *unseen* picture, and correctly classify it as either a cow or a bird. This is a typical process for what we call supervised learning, meaning, the program get to know if predictions were correct or now while training. On the other hand we have unsupervised learning, where the algorithm does not get to know if the results per se are right or wrong. We could try this with the cow and bird example as well. In this situation, the model could try to come up with the different classes of pictures it is getting fed. If we are lucky, it will find two classes; which appears to be cows and birds. But the model will not "know" what cow and birds are per se, but it learned that the collection of pictures have usually the properties of a bird or a cow. However it could turn out to classify pictures into the classes with respect to the picture having a forrest in it or not.

![center](/figs/2017-08-23-intro-ML/cow_bird.png)



![center](/figs/2017-08-23-intro-ML/image_recognition.jpg)



Meaning, with AI we do not attempt to uncover the underlying mechanisms that explains the world. It is a pure statistical exercise. For instance, in classical mechanics from physics, scientists have also done a massive load of statistics, together with theoretical work, to determine theoretical relationships between force, mass, momentum, etc. We have ended up with theoretical equations which are good approximations of the reality. With AI, we do not get a nice theoretical framework, but go all in with the statistics to fit our model. Thus it can feel more "black box", since we never land on any theoretical and easy understandable relationships that explains what we are predicting. On the other hand, it is on the same time quite easy to craps; what we do is to statistically fit some model, thats it. 

But how does AI differ from statistics? It is again a sub-branch of statistics

However, we will now dig into the concept of Machine Learning (ML). ML is less rocket science than you would think

[Intro xgboost](https://xgboost.readthedocs.io/en/latest/model.html)


